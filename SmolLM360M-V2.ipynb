{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"jatinmehra/NegaBot-Product-Criticism-Catcher\")\ntokenizer = AutoTokenizer.from_pretrained(\"jatinmehra/NegaBot-Product-Criticism-Catcher\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:27:19.420987Z","iopub.execute_input":"2025-07-24T07:27:19.421238Z","iopub.status.idle":"2025-07-24T07:28:58.186927Z","shell.execute_reply.started":"2025-07-24T07:27:19.421217Z","shell.execute_reply":"2025-07-24T07:28:58.186285Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f698f396cc6e4b9880056740c0a7421d"}},"metadata":{}},{"name":"stderr","text":"2025-07-24 07:27:34.415475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753342054.592090      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753342054.646499      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0fcc48f4604794909c33eb62c86469"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1fa8c7160b94475941eee417d5e210e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8caad20cfa8c4a08adbbf0671ad2327b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce25fac508db43d9a23cb4aebfa14fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"790c327f20564d03b4d2be3e8b0a894f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27bd8c50b7b042b88f8080fb889b1df5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/969 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96cecfb309034e9cb49cefa4c67419eb"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nsynthetic_data = pd.read_csv(\"/kaggle/input/synthetic-data/product_sentiment_dataset_2k.csv\")\nsynthetic_data.rename({'text':'tweet'}, axis=1, inplace=True)\nsynthetic_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:28:58.188316Z","iopub.execute_input":"2025-07-24T07:28:58.188903Z","iopub.status.idle":"2025-07-24T07:28:58.219747Z","shell.execute_reply.started":"2025-07-24T07:28:58.188882Z","shell.execute_reply":"2025-07-24T07:28:58.219055Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                               tweet  label\n0  Such a smart mouse — it outsmarts me by refusi...      1\n1  This printer is so efficient at doing nothing,...      1\n2  The performance of this vacuum cleaner is top-...      0\n3  This fan is the Houdini of gadgets — it disapp...      1\n4  Absolutely love how this smartwatch turns on, ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Such a smart mouse — it outsmarts me by refusi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This printer is so efficient at doing nothing,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The performance of this vacuum cleaner is top-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This fan is the Houdini of gadgets — it disapp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Absolutely love how this smartwatch turns on, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"real = pd.read_csv(\"/kaggle/input/tweet-real/real.csv\").drop(columns=[\"Unnamed: 0\"])\nreal.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:28:58.220390Z","iopub.execute_input":"2025-07-24T07:28:58.220575Z","iopub.status.idle":"2025-07-24T07:29:00.291666Z","shell.execute_reply.started":"2025-07-24T07:28:58.220560Z","shell.execute_reply":"2025-07-24T07:29:00.290991Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"     id  label                                              tweet\n0   907      1  My iPhone! It sucks! Keeps screwing up! Shut o...\n1  3557      0  Flower Art #flower #art #colour #photography #...\n2  2044      0  got my #ps4 with a copy of killzone shadow fal...\n3  1265      0  Coffee Is Love ! #iphoneography #instagram #ip...\n4  5338      0  I'm sure my iPhone just deleted every text mes...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>907</td>\n      <td>1</td>\n      <td>My iPhone! It sucks! Keeps screwing up! Shut o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3557</td>\n      <td>0</td>\n      <td>Flower Art #flower #art #colour #photography #...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2044</td>\n      <td>0</td>\n      <td>got my #ps4 with a copy of killzone shadow fal...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1265</td>\n      <td>0</td>\n      <td>Coffee Is Love ! #iphoneography #instagram #ip...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5338</td>\n      <td>0</td>\n      <td>I'm sure my iPhone just deleted every text mes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df = pd.concat([synthetic_data, real]).drop(columns=['id'])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:00.292365Z","iopub.execute_input":"2025-07-24T07:29:00.292619Z","iopub.status.idle":"2025-07-24T07:29:00.302910Z","shell.execute_reply.started":"2025-07-24T07:29:00.292600Z","shell.execute_reply":"2025-07-24T07:29:00.302390Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               tweet  label\n0  Such a smart mouse — it outsmarts me by refusi...      1\n1  This printer is so efficient at doing nothing,...      1\n2  The performance of this vacuum cleaner is top-...      0\n3  This fan is the Houdini of gadgets — it disapp...      1\n4  Absolutely love how this smartwatch turns on, ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Such a smart mouse — it outsmarts me by refusi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This printer is so efficient at doing nothing,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The performance of this vacuum cleaner is top-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This fan is the Houdini of gadgets — it disapp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Absolutely love how this smartwatch turns on, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\ntrain, valid = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:00.304637Z","iopub.execute_input":"2025-07-24T07:29:00.304874Z","iopub.status.idle":"2025-07-24T07:29:00.334010Z","shell.execute_reply.started":"2025-07-24T07:29:00.304849Z","shell.execute_reply":"2025-07-24T07:29:00.333526Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from datasets import Dataset\n\nCOLS = ['tweet', 'label']\n\ntrain_df_clean = train[COLS].copy()\nval_df_clean = valid[COLS].copy()\n\n# Ensure labels are proper integers\ntrain_df_clean['label'] = train_df_clean['label'].astype(np.int64)\nval_df_clean['label'] = val_df_clean['label'].astype(np.int64)\n\n# Reset index to ensure clean DataFrame structure\ntrain_df_clean = train_df_clean.reset_index(drop=True)\nval_df_clean = val_df_clean.reset_index(drop=True)\n\n# Create datasets with explicit copy to avoid NumPy 2.0 issues\ntrain_ds = Dataset.from_pandas(train_df_clean, preserve_index=False)\nval_ds = Dataset.from_pandas(val_df_clean, preserve_index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:00.334647Z","iopub.execute_input":"2025-07-24T07:29:00.334855Z","iopub.status.idle":"2025-07-24T07:29:01.174035Z","shell.execute_reply.started":"2025-07-24T07:29:00.334839Z","shell.execute_reply":"2025-07-24T07:29:01.173489Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def tokenize(batch):\n    \"\"\"Tokenizes a batch of text inputs.\"\"\"\n    return tokenizer(batch[\"tweet\"], truncation=True, max_length=256)\n\n# Apply tokenization\ntrain_ds = train_ds.map(tokenize, batched=True, remove_columns=['tweet'])\nval_ds = val_ds.map(tokenize, batched=True, remove_columns=['tweet'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:01.174690Z","iopub.execute_input":"2025-07-24T07:29:01.175062Z","iopub.status.idle":"2025-07-24T07:29:01.438890Z","shell.execute_reply.started":"2025-07-24T07:29:01.175046Z","shell.execute_reply":"2025-07-24T07:29:01.438086Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2867 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26780a4534314003bde4c24635f239b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/717 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"758cb1cfa7124f8a95a52eff8a6823aa"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"\n# Add a new padding token\n\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\n# Resize the model's token embeddings to match the new tokenizer\n\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Set the pad token id in the model's config\n\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:01.439732Z","iopub.execute_input":"2025-07-24T07:29:01.439971Z","iopub.status.idle":"2025-07-24T07:29:01.456370Z","shell.execute_reply.started":"2025-07-24T07:29:01.439945Z","shell.execute_reply":"2025-07-24T07:29:01.455630Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n\nDIR = \"/kaggle/working/\"\n# --- Training Arguments ---\ntraining_args = TrainingArguments(\n    output_dir=f\"/kaggle/working/Chkpts\",\n    do_train=True,\n    do_eval=True,\n    eval_strategy=\"steps\", # Evaluate every 'eval_steps'\n    save_strategy=\"steps\", # Save model every 'save_steps'\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=24,\n    learning_rate=1e-5,\n    logging_dir=\"./logs\",\n    logging_steps=200,\n    save_steps=200,\n    eval_steps=200,\n    weight_decay=0.05,\n    save_total_limit=1, # Only save the best model\n    metric_for_best_model=\"accuracy\",\n    greater_is_better=True,\n    load_best_model_at_end=True, # Load the best model found during training\n    report_to=\"none\", # Do not report to external services like Weights & Biases\n    warmup_ratio=0.1, # 10% of total steps will be used for linear warmup\n    lr_scheduler_type=\"cosine\", # Use cosine learning rate decay\n    dataloader_pin_memory=False, # Disable pin memory to avoid potential issues\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:01.457153Z","iopub.execute_input":"2025-07-24T07:29:01.457443Z","iopub.status.idle":"2025-07-24T07:29:03.051201Z","shell.execute_reply.started":"2025-07-24T07:29:01.457421Z","shell.execute_reply":"2025-07-24T07:29:03.050652Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score\nfrom scipy.special import softmax\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = softmax(logits, axis=-1)[:, 1] \n    preds = logits.argmax(axis=-1)\n    \n    acc = accuracy_score(labels, preds)\n    auc = roc_auc_score(labels, probs)\n    \n    return {\n        \"accuracy\": acc,\n        \"roc_auc\": auc\n    }\n\n\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntrainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_ds,\n        eval_dataset=val_ds,\n        processing_class=tokenizer,\n        compute_metrics=compute_metrics,\n        data_collator=data_collator, \n    )\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:29:03.051940Z","iopub.execute_input":"2025-07-24T07:29:03.052172Z","iopub.status.idle":"2025-07-24T07:34:22.612188Z","shell.execute_reply.started":"2025-07-24T07:29:03.052152Z","shell.execute_reply":"2025-07-24T07:34:22.611608Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [540/540 05:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.183300</td>\n      <td>0.085891</td>\n      <td>0.972106</td>\n      <td>0.995584</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.064300</td>\n      <td>0.095588</td>\n      <td>0.969317</td>\n      <td>0.995445</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=540, training_loss=0.10341257607495344, metrics={'train_runtime': 317.6473, 'train_samples_per_second': 27.077, 'train_steps_per_second': 1.7, 'total_flos': 1257584431864320.0, 'train_loss': 0.10341257607495344, 'epoch': 3.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/real-tweet-data/test_oJQbWVk.csv\")\n\nds_test = Dataset.from_pandas(test[['tweet']])\nds_test = ds_test.map(tokenize, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:34:22.612983Z","iopub.execute_input":"2025-07-24T07:34:22.613261Z","iopub.status.idle":"2025-07-24T07:34:22.802754Z","shell.execute_reply.started":"2025-07-24T07:34:22.613221Z","shell.execute_reply":"2025-07-24T07:34:22.802164Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1953 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a9b02ee0364b38bb2f6044b2510f18"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"predictions = trainer.predict(ds_test)\nprobs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:34:22.803605Z","iopub.execute_input":"2025-07-24T07:34:22.804212Z","iopub.status.idle":"2025-07-24T07:35:01.768484Z","shell.execute_reply.started":"2025-07-24T07:34:22.804192Z","shell.execute_reply":"2025-07-24T07:35:01.767711Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"predicted_labels = probs.argmax(axis=1)\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"label\": predicted_labels \n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:35:01.769424Z","iopub.execute_input":"2025-07-24T07:35:01.769731Z","iopub.status.idle":"2025-07-24T07:35:01.780286Z","shell.execute_reply.started":"2025-07-24T07:35:01.769714Z","shell.execute_reply":"2025-07-24T07:35:01.779668Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/Best_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:35:01.782442Z","iopub.execute_input":"2025-07-24T07:35:01.782706Z","iopub.status.idle":"2025-07-24T07:35:04.574013Z","shell.execute_reply.started":"2025-07-24T07:35:01.782682Z","shell.execute_reply":"2025-07-24T07:35:04.573230Z"}},"outputs":[],"execution_count":14}]}